{
  "timestamp": "2026-02-07 10:57:00",
  "model": "gemini-2.0-flash-lite",
  "evaluator": "gemini-2.0-flash-lite + mistral-embeddings",
  "sample_count": 47,
  "overall_scores": {
    "faithfulness": 0.473,
    "answer_relevancy": 0.112,
    "context_precision": 0.595,
    "context_recall": 0.596
  },
  "category_scores": [
    {
      "category": "simple",
      "count": 12,
      "faithfulness": 0.444,
      "answer_relevancy": 0.246,
      "context_precision": 0.780,
      "context_recall": 0.667
    },
    {
      "category": "complex",
      "count": 12,
      "faithfulness": 0.547,
      "answer_relevancy": 0.000,
      "context_precision": 0.529,
      "context_recall": 0.375
    },
    {
      "category": "noisy",
      "count": 11,
      "faithfulness": 0.313,
      "answer_relevancy": 0.148,
      "context_precision": 0.756,
      "context_recall": 0.773
    },
    {
      "category": "conversational",
      "count": 12,
      "faithfulness": 0.574,
      "answer_relevancy": 0.058,
      "context_precision": 0.491,
      "context_recall": 0.583
    }
  ],
  "configuration": {
    "vector_store": "FAISS",
    "embedding_model": "mistral-embed",
    "embedding_dimensions": 1024,
    "total_chunks": 302,
    "retrieval_k": 5,
    "similarity_metric": "cosine",
    "llm_temperature": 0.7,
    "llm_max_tokens": "unlimited"
  },
  "test_cases": {
    "total": 47,
    "categories": {
      "simple": {
        "count": 12,
        "description": "Direct factual questions",
        "example": "Who is the leading scorer in the NBA?"
      },
      "complex": {
        "count": 12,
        "description": "Multi-part or analytical questions",
        "example": "Compare the offensive efficiency of the top 3 scoring teams"
      },
      "noisy": {
        "count": 11,
        "description": "Typos, poor grammar, vague references",
        "example": "stats for that tall guy from milwaukee"
      },
      "conversational": {
        "count": 12,
        "description": "Follow-up questions with context",
        "example": "Who is their best player statistically?"
      }
    }
  },
  "key_findings": {
    "critical_issues": [
      "Answer Relevancy (0.112) - Responses not focused on questions",
      "Complex query Answer Relevancy (0.000) - Complete failure mode",
      "Faithfulness (0.473) - Nearly half of content unsupported"
    ],
    "acceptable_areas": [
      "Context Precision (0.595) - Retrieval finds relevant chunks",
      "Context Recall (0.596) - Most needed info is retrieved"
    ],
    "priority_improvements": [
      "1. Improve prompt engineering for concise answers",
      "2. Reduce LLM temperature for factual responses",
      "3. Add source attribution to reduce hallucinations",
      "4. Implement answer extraction post-processing",
      "5. Add query classification for complex questions"
    ]
  },
  "expected_improvements": {
    "after_phase_1": {
      "faithfulness": 0.65,
      "answer_relevancy": 0.60,
      "context_precision": 0.60,
      "context_recall": 0.65
    },
    "after_all_phases": {
      "faithfulness": 0.75,
      "answer_relevancy": 0.70,
      "context_precision": 0.70,
      "context_recall": 0.75
    },
    "target": {
      "faithfulness": 0.80,
      "answer_relevancy": 0.75,
      "context_precision": 0.75,
      "context_recall": 0.80
    }
  }
}

{
  "timestamp": "2026-02-08 02:15:32",
  "phase": "Phase 6 - Retrieval Quality (Quality Filter + Content Metadata)",
  "prompt_variation": "english_detailed",
  "prompt_template": "You are '{app_name} Analyst AI', an expert NBA sports analysis assistant.\n\nCONTEXT:\n---\n{context}\n---\n\nUSER QUESTION:\n{question}\n\nINSTRUCTIONS:\n1. Answer the question directly and precisely\n2. Base your answer on the context provided above\n3. Be concise and factual\n4. Cite sources when relevant\n5. If information is not in the context, briefly state that\n\nANSWER:",
  "model": "gemini-2.0-flash-lite",
  "sample_count": 47,
  "improvements": [
    "quality_filter",
    "content_based_metadata",
    "metadata_aware_search",
    "hybrid_search",
    "conservative_classification",
    "sql_fallback",
    "optimized_prompt"
  ],
  "overall_scores": {
    "faithfulness": 0.5849123904881102,
    "answer_relevancy": 0.15245691420560634,
    "context_precision": 0.69193262408644,
    "context_recall": 0.5780141843971631
  },
  "category_scores": [
    {
      "category": "simple",
      "count": 12,
      "faithfulness": 0.6944444444444443,
      "answer_relevancy": 0.0,
      "context_precision": 0.8620370370099923,
      "context_recall": 0.375
    },
    {
      "category": "complex",
      "count": 12,
      "faithfulness": 0.7131944444444445,
      "answer_relevancy": 0.13599076489278472,
      "context_precision": 0.5513888888657639,
      "context_recall": 0.625
    },
    {
      "category": "noisy",
      "count": 11,
      "faithfulness": 0.5150802139037434,
      "answer_relevancy": 0.12561512091531576,
      "context_precision": 0.6569444444162363,
      "context_recall": 0.8636363636363636
    },
    {
      "category": "conversational",
      "count": 12,
      "faithfulness": 0.41111111111111115,
      "answer_relevancy": 0.34598495490680065,
      "context_precision": 0.6944444444145833,
      "context_recall": 0.47222222222222227
    }
  ]
}